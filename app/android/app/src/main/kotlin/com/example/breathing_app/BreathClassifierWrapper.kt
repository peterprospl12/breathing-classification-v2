package com.example.breathing_app

import android.content.Context
import android.os.Build
import android.util.Log
import ai.onnxruntime.OnnxTensor
import ai.onnxruntime.OrtEnvironment
import ai.onnxruntime.OrtSession
import java.io.File
import java.io.FileOutputStream
import java.nio.FloatBuffer
import java.util.concurrent.locks.ReentrantLock
import org.jtransforms.fft.FloatFFT_1D
import kotlin.math.*

class MelSpectrogramExtractor(
    private val sampleRate: Int = 44100,
    public val nFFT: Int = 1024,
    public val hopLength: Int = 512,
    private val nMels: Int = 40,
    private val fMin: Float = 0f,
    private val fMax: Float = (sampleRate / 2).toFloat()
) {
    private val fft = FloatFFT_1D(nFFT.toLong())
    private val melFilterBank: Array<FloatArray>

    init {
        melFilterBank = createMelFilterBank()
    }

    private fun hzToMel(freq: Float): Float {
        return 2595f * log10(1f + freq / 700f)
    }

    private fun melToHz(mel: Float): Float {
        return 700f * (10f.pow(mel / 2595f) - 1f)
    }

    private fun createMelFilterBank(): Array<FloatArray> {
        val fftBins = nFFT / 2 + 1
        val melMin = hzToMel(fMin)
        val melMax = hzToMel(fMax)
        val melPoints = FloatArray(nMels + 2) { i ->
            melMin + (melMax - melMin) * i / (nMels + 1)
        }
        val hzPoints = melPoints.map { melToHz(it) }
        val binFrequencies = FloatArray(fftBins) { i -> i * sampleRate.toFloat() / nFFT }

        val filterBank = Array(nMels) { FloatArray(fftBins) }
        for (m in 1..nMels) {
            val fLeft = hzPoints[m - 1]
            val fCenter = hzPoints[m]
            val fRight = hzPoints[m + 1]
            for (k in 0 until fftBins) {
                val freq = binFrequencies[k]
                val weight = when {
                    freq < fLeft -> 0f
                    freq <= fCenter -> (freq - fLeft) / (fCenter - fLeft)
                    freq <= fRight -> (fRight - freq) / (fRight - fCenter)
                    else -> 0f
                }
                filterBank[m - 1][k] = weight
            }
        }
        return filterBank
    }

    fun extract(audio: FloatArray): Pair<FloatArray, Int> {
        // Number of frames
        val numFrames = 1 + (audio.size - nFFT) / hopLength
        // Mel-spectrogram: [nMels][numFrames]
        val melSpec = Array(nMels) { FloatArray(numFrames) }
        val window = FloatArray(nFFT) { i ->
            // Hamming window
            (0.54f - 0.46f * cos(2.0 * PI.toFloat() * i / (nFFT - 1))).toFloat()
        }
        val frameBuffer = FloatArray(nFFT * 2) // interleaved real+imag for JTransforms

        for (frame in 0 until numFrames) {
            val offset = frame * hopLength
            // Copy windowed signal
            val real = FloatArray(nFFT) { i ->
                val idx = offset + i
                if (idx < audio.size) audio[idx] * window[i] else 0f
            }
            // prepare interleaved buffer: real, imag
            for (i in 0 until nFFT) {
                frameBuffer[2 * i] = real[i]
                frameBuffer[2 * i + 1] = 0f
            }
            // FFT
            fft.complexForward(frameBuffer)
            // power spectrum
            val fftBins = nFFT / 2 + 1
            val powerSpec = FloatArray(fftBins) { k ->
                val re = frameBuffer[2 * k]
                val im = frameBuffer[2 * k + 1]
                (re * re + im * im)
            }
            // apply mel filter bank
            for (m in 0 until nMels) {
                var sum = 0f
                for (k in 0 until fftBins) {
                    sum += melFilterBank[m][k] * powerSpec[k]
                }
                // log-mel
                melSpec[m][frame] = ln(sum + 1e-9f)
            }
        }
        // Flatten to [nMels * numFrames]
        val flat = FloatArray(nMels * numFrames)
        for (m in 0 until nMels) {
            for (f in 0 until numFrames) {
                flat[m * numFrames + f] = melSpec[m][f]
            }
        }
        return Pair(flat, numFrames)
    }

    /**
     * Wraps mel-spectrogram into FloatBuffer and returns tensor shape
     * Shape for ONNX: [1, 1, nMels, numFrames]
     */
    fun toTensor(env: OrtEnvironment, melFlat: FloatArray, numFrames: Int): OnnxTensor {
        val buf = FloatBuffer.wrap(melFlat)
        val shape = longArrayOf(1, 1, nMels.toLong(), numFrames.toLong())
        return OnnxTensor.createTensor(env, buf, shape)
    }
}

/**
 * Wrapper dla modelu ONNX klasyfikacji oddech√≥w.
 * Obs≈Çuguje inicjalizacjƒô modelu, klasyfikacjƒô audio i zarzƒÖdzanie zasobami.
 */
class BreathClassifierWrapper(private val context: Context) {
    private val TAG = "BreathClassifierWrapper"
    private val env: OrtEnvironment = OrtEnvironment.getEnvironment()
    private var session: OrtSession? = null
    private val sessionLock = ReentrantLock() // Do bezpiecznego dostƒôpu wielowƒÖtkowego
    private val melExtractor = MelSpectrogramExtractor()

    companion object {
        const val MODEL_NAME = "breath_classifier_model_mel_input.onnx"
        const val MODEL_DATA_NAME = "breath_classifier_model_mel_input.onnx.data"
        // R√≥≈ºne mo≈ºliwe ≈õcie≈ºki do modelu w zasobach
        private val POSSIBLE_ASSET_PATHS = arrayOf(
            "flutter_assets/assets/models/$MODEL_NAME",
            "assets/models/$MODEL_NAME",
            "models/$MODEL_NAME"
        )
        // R√≥≈ºne mo≈ºliwe ≈õcie≈ºki do pliku danych modelu w zasobach
        private val POSSIBLE_DATA_ASSET_PATHS = arrayOf(
            "flutter_assets/assets/models/$MODEL_DATA_NAME",
            "assets/models/$MODEL_DATA_NAME",
            "models/$MODEL_DATA_NAME"
        )
    }

    // Funkcja do wy≈õwietlania log√≥w, kt√≥re bƒôdƒÖ lepiej widoczne w terminalu Flutter
    private fun logInfo(message: String) {
        Log.i(TAG, "BREATH_CLASSIFIER_INFO: $message")
        println("BREATH_CLASSIFIER_INFO: $message")
    }

    private fun logError(message: String, e: Exception? = null) {
        Log.e(TAG, "BREATH_CLASSIFIER_ERROR: $message")
        println("BREATH_CLASSIFIER_ERROR: $message")
        e?.let {
            Log.e(TAG, "BREATH_CLASSIFIER_ERROR: ${e.message}")
            println("BREATH_CLASSIFIER_ERROR: ${e.message}")
            println("BREATH_CLASSIFIER_ERROR_STACK: ${e.stackTraceToString()}")
        }
    }

    /**
     * Kopiuje model z assets do lokalnego pliku i inicjalizuje sesjƒô ONNX Runtime
     * @return Boolean - czy inicjalizacja zako≈Ñczy≈Ça siƒô powodzeniem
     */
    fun initialize(): Boolean {
        logInfo("‚û°Ô∏è Rozpoczƒôcie inicjalizacji klasyfikatora")
        return try {
            logDeviceInfo() // Logowanie informacji o urzƒÖdzeniu do debugowania

            val modelFile = File(context.filesDir, MODEL_NAME)
            val modelDataFile = File(context.filesDir, MODEL_DATA_NAME)

            // Wypisz zawarto≈õƒá katalogu assets do debugowania
            logInfo("üìÅ Zawarto≈õƒá g≈Ç√≥wnego katalogu assets:")
            listAvailableAssets("")
            logInfo("üìÅ Zawarto≈õƒá katalogu flutter_assets:")
            listAvailableAssets("flutter_assets")
            logInfo("üìÅ Zawarto≈õƒá katalogu flutter_assets/assets:")
            listAvailableAssets("flutter_assets/assets")
            logInfo("üìÅ Zawarto≈õƒá katalogu flutter_assets/assets/models:")
            listAvailableAssets("flutter_assets/assets/models")

            // Kopiowanie pliku modelu
            if (!modelFile.exists()) {
                logInfo("üì¶ Model nie istnieje lokalnie, kopiowanie z assets...")
                copyModelFromAssets(modelFile)

                // Upewnij siƒô, ≈ºe plik faktycznie zosta≈Ç utworzony
                if (!modelFile.exists() || modelFile.length() == 0L) {
                    throw Exception("Nie uda≈Ço siƒô prawid≈Çowo skopiowaƒá pliku modelu")
                }
            }

            // Kopiowanie pliku danych modelu
            if (!modelDataFile.exists()) {
                logInfo("üì¶ Plik danych modelu nie istnieje lokalnie, kopiowanie z assets...")
                copyModelDataFromAssets(modelDataFile)
            }

            // Sprawd≈∫ i wypisz stan pliku modelu
            logInfo("üìÑ ≈öcie≈ºka do modelu: ${modelFile.absolutePath}, Rozmiar: ${modelFile.length()} bajt√≥w")
            logInfo("üìÑ Model istnieje: ${modelFile.exists()}, Mo≈ºna czytaƒá: ${modelFile.canRead()}")

            if (modelDataFile.exists()) {
                logInfo("üìÑ ≈öcie≈ºka do danych modelu: ${modelDataFile.absolutePath}, Rozmiar: ${modelDataFile.length()} bajt√≥w")
                logInfo("üìÑ Plik danych modelu istnieje: ${modelDataFile.exists()}, Mo≈ºna czytaƒá: ${modelDataFile.canRead()}")
            } else {
                logInfo("‚ö†Ô∏è Plik danych modelu (.data) nie istnieje, kontynuujemy bez niego")
            }

            // Wypisz zawarto≈õƒá katalogu z modelem
            val filesDir = context.filesDir
            logInfo("üìÅ Zawarto≈õƒá katalogu filesDir (${filesDir.absolutePath}):")
            filesDir.listFiles()?.forEach { file ->
                logInfo("   - ${file.name}: ${file.length()} bajt√≥w")
            }

            // Pr√≥bujemy utworzyƒá sesjƒô z pliku
            val success = createSessionFromFile(modelFile)

            // Je≈õli nie uda≈Ço siƒô z pliku, pr√≥bujemy utworzyƒá sesjƒô bezpo≈õrednio z byt√≥w modelu
            if (!success) {
                logInfo("üîÑ Pr√≥ba utworzenia sesji bezpo≈õrednio z bajt√≥w modelu...")
                createSessionFromBytes()
            }

            // Sprawd≈∫ czy sesja zosta≈Ça utworzona
            val initialized = session != null
            if (initialized) {
                logInfo("‚úÖ Sesja utworzona pomy≈õlnie")
            } else {
                logError("‚ùå Nie uda≈Ço siƒô utworzyƒá sesji ONNX")
            }

            initialized
        } catch (e: Exception) {
            logError("‚ùå B≈ÇƒÖd inicjalizacji modelu", e)
            false
        }
    }

    /**
     * Pr√≥buje utworzyƒá sesjƒô ONNX z pliku
     */
    private fun createSessionFromFile(modelFile: File): Boolean {
        return try {
            // Konfiguracja opcji sesji
            val opts = OrtSession.SessionOptions()
            opts.setIntraOpNumThreads(2) // Wykorzystaj maksymalnie 2 wƒÖtki do oblicze≈Ñ

            // Utw√≥rz sesjƒô
            sessionLock.lock()
            try {
                logInfo("üîÑ Tworzenie sesji ONNX Runtime z pliku...")
                session = env.createSession(modelFile.absolutePath, opts)
                logInfo("‚úÖ Model ONNX za≈Çadowany pomy≈õlnie z pliku")

                // Wypisz informacje o wej≈õciach i wyj≈õciach modelu
                session?.let { sess ->
                    logInfo("üìä Informacje o modelu:")
                    logInfo("üì• Wej≈õcia modelu: ${sess.inputNames.joinToString(", ")}")
                    logInfo("üì§ Wyj≈õcia modelu: ${sess.outputNames.joinToString(", ")}")
                }
                true
            } finally {
                sessionLock.unlock()
            }
        } catch (e: Exception) {
            logError("‚ö†Ô∏è Nie uda≈Ço siƒô utworzyƒá sesji z pliku: ${e.message}", e)
            false
        }
    }

    /**
     * Pr√≥buje utworzyƒá sesjƒô ONNX bezpo≈õrednio z bajt√≥w modelu
     */
    private fun createSessionFromBytes(): Boolean {
        return try {
            var modelBytes: ByteArray? = null

            // Pr√≥bujemy ka≈ºdƒÖ mo≈ºliwƒÖ ≈õcie≈ºkƒô, dop√≥ki odczyt siƒô nie powiedzie
            for (assetPath in POSSIBLE_ASSET_PATHS) {
                try {
                    logInfo("üîÑ Pr√≥ba odczytu modelu z: $assetPath")
                    context.assets.open(assetPath).use { input ->
                        modelBytes = input.readBytes()
                    }
                    logInfo("‚úÖ Odczytano model z $assetPath, rozmiar: ${modelBytes?.size ?: 0} bajt√≥w")
                    break  // Je≈õli odczyt siƒô powi√≥d≈Ç, ko≈Ñczymy pƒôtlƒô
                } catch (e: Exception) {
                    logError("‚ùå Nie mo≈ºna odczytaƒá modelu z ≈õcie≈ºki: $assetPath - ${e.message}")
                }
            }

            if (modelBytes == null || modelBytes!!.isEmpty()) {
                logError("‚ùå Nie uda≈Ço siƒô odczytaƒá modelu z ≈ºadnej ≈õcie≈ºki")
                return false
            }

            // Konfiguracja opcji sesji
            val opts = OrtSession.SessionOptions()
            opts.setIntraOpNumThreads(2)

            sessionLock.lock()
            try {
                logInfo("üîÑ Tworzenie sesji ONNX Runtime z bajt√≥w...")
                session = env.createSession(modelBytes!!, opts)
                logInfo("‚úÖ Model ONNX za≈Çadowany pomy≈õlnie z bajt√≥w")

                // Wypisz informacje o wej≈õciach i wyj≈õciach modelu
                session?.let { sess ->
                    logInfo("üìä Informacje o modelu:")
                    logInfo("üì• Wej≈õcia modelu: ${sess.inputNames.joinToString(", ")}")
                    logInfo("üì§ Wyj≈õcia modelu: ${sess.outputNames.joinToString(", ")}")
                }
                true
            } finally {
                sessionLock.unlock()
            }
        } catch (e: Exception) {
            logError("‚ùå Nie uda≈Ço siƒô utworzyƒá sesji z bajt√≥w modelu", e)
            false
        }
    }

    /**
     * Kopiuje plik modelu z zasob√≥w do lokalnego pliku
     */
    private fun copyModelFromAssets(modelFile: File) {
        var copied = false

        // Pr√≥bujemy ka≈ºdƒÖ mo≈ºliwƒÖ ≈õcie≈ºkƒô, dop√≥ki kopiowanie siƒô nie powiedzie
        for (assetPath in POSSIBLE_ASSET_PATHS) {
            try {
                logInfo("üîÑ Pr√≥ba kopiowania modelu z: $assetPath")

                context.assets.open(assetPath).use { input ->
                    FileOutputStream(modelFile).use { output ->
                        val bytes = input.readBytes()
                        output.write(bytes)
                        output.flush()
                        logInfo("‚úÖ Skopiowano ${bytes.size} bajt√≥w")
                    }
                }

                logInfo("‚úÖ Model skopiowany z $assetPath do: ${modelFile.absolutePath}, rozmiar: ${modelFile.length()}")
                copied = true
                break  // Je≈õli kopiowanie siƒô powiod≈Ço, ko≈Ñczymy pƒôtlƒô

            } catch (e: Exception) {
                logError("‚ùå Nie mo≈ºna skopiowaƒá modelu z ≈õcie≈ºki: $assetPath - ${e.message}")
                // Kontynuuj do nastƒôpnej ≈õcie≈ºki
            }
        }

        if (!copied) {
            // Je≈õli ≈ºadna ≈õcie≈ºka nie zadzia≈Ça≈Ça, log b≈ÇƒÖd
            logError("‚ùå Nie uda≈Ço siƒô skopiowaƒá modelu z ≈ºadnej ≈õcie≈ºki.")
        }
    }

    /**
     * Kopiuje plik danych modelu (.data) z zasob√≥w do lokalnego pliku
     */
    private fun copyModelDataFromAssets(dataFile: File) {
        var copied = false

        // Pr√≥bujemy ka≈ºdƒÖ mo≈ºliwƒÖ ≈õcie≈ºkƒô, dop√≥ki kopiowanie siƒô nie powiedzie
        for (assetPath in POSSIBLE_DATA_ASSET_PATHS) {
            try {
                logInfo("üîÑ Pr√≥ba kopiowania danych modelu z: $assetPath")

                context.assets.open(assetPath).use { input ->
                    FileOutputStream(dataFile).use { output ->
                        val bytes = input.readBytes()
                        output.write(bytes)
                        output.flush()
                        logInfo("‚úÖ Skopiowano ${bytes.size} bajt√≥w danych modelu")
                    }
                }

                logInfo("‚úÖ Dane modelu skopiowane z $assetPath do: ${dataFile.absolutePath}, rozmiar: ${dataFile.length()}")
                copied = true
                break  // Je≈õli kopiowanie siƒô powiod≈Ço, ko≈Ñczymy pƒôtlƒô

            } catch (e: Exception) {
                logError("‚ùå Nie mo≈ºna skopiowaƒá danych modelu z ≈õcie≈ºki: $assetPath - ${e.message}")
                // Kontynuuj do nastƒôpnej ≈õcie≈ºki
            }
        }

        if (!copied) {
            // Je≈õli ≈ºadna ≈õcie≈ºka nie zadzia≈Ça≈Ça, log b≈ÇƒÖd
            logError("‚ùå Nie uda≈Ço siƒô skopiowaƒá danych modelu z ≈ºadnej ≈õcie≈ºki. Kontynuujemy bez nich.")
        }
    }

    /**
     * Wypisuje informacje o urzƒÖdzeniu pomocne przy debugowaniu
     */
    private fun logDeviceInfo() {
        logInfo("üì± Informacje o urzƒÖdzeniu:")
        logInfo("   - Producent: ${Build.MANUFACTURER}")
        logInfo("   - Model: ${Build.MODEL}")
        logInfo("   - Wersja SDK: ${Build.VERSION.SDK_INT}")
        logInfo("   - Wersja systemu: ${Build.VERSION.RELEASE}")
        logInfo("   - Dostƒôpna pamiƒôƒá: ${Runtime.getRuntime().maxMemory() / (1024 * 1024)} MB")
    }

    /**
     * Pomocnicza metoda do listowania plik√≥w w zasobach
     */
    private fun listAvailableAssets(path: String) {
        try {
            val files = context.assets.list(path)
            if (files.isNullOrEmpty()) {
                logInfo("   üìÅ ≈öcie≈ºka '$path' jest pusta lub nie istnieje")
            } else {
                logInfo("   üìÅ Pliki w '$path': ${files.joinToString(", ")}")
            }
        } catch (e: Exception) {
            logError("‚ùå Nie mo≈ºna wylistowaƒá plik√≥w w '$path': ${e.message}")
        }
    }

    /**
     * Klasyfikuje dane audio i zwraca indeks klasy (0-wydech, 1-wdech, 2-cisza)
     * Metoda jest thread-safe
     * @param audioData FloatArray surowych znormalizowanych danych audio [-1,1]
     * @return Int indeks klasy (0, 1, lub 2)
     */
    fun classifyAudio(audioData: FloatArray): Int {
        sessionLock.lock()
        try {
            val sess = session ?: throw IllegalStateException("Sesja nie zainicjalizowana. Wywo≈Çaj initialize() najpierw.")
            val inputName = sess.inputNames.first()

            logInfo("üîä Klasyfikacja danych audio o rozmiarze: ${audioData.size}")

            // --- Padding audio to ensure 26 frames ---
            val expectedFrames = 26
            val requiredSamples = melExtractor.run { nFFT + hopLength * (expectedFrames - 1) }
            val audioInput = if (audioData.size >= requiredSamples) {
                audioData.copyOfRange(0, requiredSamples)
            } else {
                audioData + FloatArray(requiredSamples - audioData.size)
            }
            logInfo("üîä Audio padded/truncated to $requiredSamples samples for $expectedFrames frames")

            // 1. ekstrakcja mel‚Äëspektrogramu
            val (melFlat, numFrames) = melExtractor.extract(audioInput)
            val inputTensor = melExtractor.toTensor(env, melFlat, numFrames)

            logInfo("üîä Kszta≈Çt tensora wej≈õciowego: ${inputTensor.info.shape.joinToString(", ")}")

            return inputTensor.use { input ->
                sess.run(mapOf(inputName to input)).use { output ->
                    val outputTensor = output.get(0) as OnnxTensor
                    @Suppress("UNCHECKED_CAST")
                    // Handle output shape [1, numFrames, numClasses]
                    val rawOutput = outputTensor.value as Array<Array<FloatArray>>
                    val frameScores = rawOutput[0] // [numFrames][numClasses]
                    // Aggregate class scores across frames
                    val numClasses = frameScores[0].size
                    val classScores = FloatArray(numClasses) { classIdx ->
                        frameScores.fold(0f) { sum, frameArr -> sum + frameArr[classIdx] }
                    }
                    classScores.indices.maxByOrNull { classScores[it] } ?: 2
                }
            }
        } catch (e: Exception) {
            logError("B≈ÇƒÖd w czasie klasyfikacji", e)
            return 2
        } finally {
            sessionLock.unlock()
        }
    }

    /**
     * Sprawdza, czy klasyfikator zosta≈Ç poprawnie zainicjalizowany
     */
    fun isInitialized(): Boolean {
        return session != null
    }

    /**
     * Zwalnia zasoby ONNX Runtime
     */
    fun close() {
        try {
            sessionLock.lock()
            session?.close()
            sessionLock.unlock()

            env.close()
            logInfo("Zasoby zwolnione")
        } catch (e: Exception) {
            logError("B≈ÇƒÖd podczas zwalniania zasob√≥w", e)
        }
    }
}