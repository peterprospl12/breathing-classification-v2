{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Data preprocessing**",
   "id": "f60c5ddf4c188baa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T22:15:08.284432Z",
     "start_time": "2025-01-26T22:12:14.389405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import librosa\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "REFRESH_TIME = 0.25  # seconds\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Directories with data\n",
    "data_dir = '../data/train'\n",
    "\n",
    "# Function to load labels from csv file\n",
    "def load_labels(csv_filee):\n",
    "    labels_c = []\n",
    "    with open(csv_filee, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            labels_c.append((int(row[0]), float(row[1])))\n",
    "    return labels_c\n",
    "\n",
    "# Function to get the label for a given time\n",
    "def get_label_for_time(labels_t, time_t):\n",
    "    elapsed_time = 0\n",
    "    for label_t, duration in labels_t:\n",
    "        elapsed_time += duration\n",
    "        if time_t < elapsed_time:\n",
    "            return label_t\n",
    "    return labels_t[-1][0]  # Return the last label if time exceeds total duration\n",
    "\n",
    "# Creating list of files\n",
    "wav_files = [os.path.join(data_dir, file) for file in os.listdir(data_dir) if file.endswith('.wav')]\n",
    "train_data = []\n",
    "\n",
    "# Main loop to preprocess data into MFCCs\n",
    "for wav_file in wav_files:\n",
    "    csv_file = wav_file.replace('.wav', '.csv')\n",
    "    if not os.path.exists(csv_file):\n",
    "        continue\n",
    "\n",
    "    # Load audio and labels\n",
    "    y, sr = librosa.load(wav_file, mono=True)\n",
    "    labels = load_labels(csv_file)\n",
    "\n",
    "    # Calculate chunk size\n",
    "    chunk_size = int(sr * REFRESH_TIME)\n",
    "\n",
    "    # List of MFCCs for every data sequence (it will be a list of lists of tuples (mfcc coefficients, label))\n",
    "    mfcc_sequence = []\n",
    "\n",
    "    # Iterate through every 0.25s audio chunk\n",
    "    for i in range(0, len(y), chunk_size):\n",
    "        frame = y[i:i + chunk_size]\n",
    "        if len(frame) == chunk_size:\n",
    "            mfcc = librosa.feature.mfcc(y=frame, sr=sr)\n",
    "            mfcc_mean = mfcc.mean(axis=1)\n",
    "            time = i / sr * 1000  # Convert to milliseconds\n",
    "            label = get_label_for_time(labels, time)\n",
    "            mfcc_sequence.append((mfcc_mean, label))\n",
    "\n",
    "    if mfcc_sequence:\n",
    "        train_data.append(mfcc_sequence)"
   ],
   "id": "2e259d6856399c02",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T22:15:14.843883Z",
     "start_time": "2025-01-26T22:15:14.839018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check length of every sequence\n",
    "\n",
    "lengths = [len(seq) for seq in train_data]\n",
    "print(\"Min length: \", min(lengths))\n",
    "print(\"Max length: \", max(lengths))\n",
    "print(lengths)"
   ],
   "id": "15d263ccff2a2af6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min length:  50\n",
      "Max length:  140\n",
      "[122, 132, 120, 123, 124, 124, 124, 123, 120, 50, 121, 128, 125, 121, 127, 124, 140, 125, 124, 121, 122, 124, 123, 126, 125, 120, 123, 122, 123, 124, 125, 124, 125, 126, 120, 121, 121, 122, 120, 128, 120, 127, 126, 125, 120, 126, 121, 121, 127, 124, 124, 120, 121, 126, 122, 125, 120, 121, 125, 121, 120, 120, 120, 125, 122, 122, 124, 123, 123, 124, 124, 131, 120, 129, 121, 125, 126, 120, 121, 122, 125, 123, 126, 121, 120, 120, 122, 122, 120, 121, 125, 121, 123, 123, 120, 122, 121, 123, 121, 135, 123, 121, 121, 123, 122, 120, 124, 120, 122, 121, 128, 121, 123, 121, 129, 136, 131, 125, 122, 122, 121, 130, 125, 124, 121, 123, 126, 123, 121, 120, 123, 121, 122, 124, 131, 125, 120, 122, 120, 123, 121, 120, 123, 120, 120, 123, 120, 120, 124, 121, 120, 124, 122, 123, 130, 120, 121, 120, 125, 124, 122, 123, 124, 122, 122, 126, 125, 123, 121, 121, 126, 120, 124, 126, 127, 124, 129, 122, 125, 120, 121, 124, 122, 121, 129, 124, 131, 123, 120, 121, 125, 121, 122, 120, 126, 129, 125, 122, 121, 131, 121, 129, 127, 121, 120, 123, 123, 125, 124, 125, 122, 125, 120, 121, 123, 123, 121, 122, 122, 122, 124, 120, 121, 120, 127, 124, 127, 125, 121, 122, 120, 121, 127, 126, 120, 122, 121, 123, 120, 127, 121, 121, 129, 121, 121, 120, 127, 123, 121, 122, 122, 123, 123, 121, 123, 122, 120, 124, 121, 122, 120, 124, 125, 127, 120, 122, 134, 125, 121, 125, 123, 121, 123, 124, 122, 124, 124, 124, 127, 120, 131, 126, 122, 125, 120, 121, 121, 123, 122, 120, 123, 122, 126, 126, 121, 134, 124, 123, 125, 120, 121, 125, 124, 120, 121, 124, 122, 124, 125, 120, 120, 123, 121, 120, 121, 136, 120, 120, 131]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Data Loader**",
   "id": "9ca0c0d1656d1e1a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T22:15:24.211353Z",
     "start_time": "2025-01-26T22:15:24.202099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split data into train and validation sets\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2)\n",
    "\n",
    "# DataLoader and collate function\n",
    "from model_classes import AudioDataset\n",
    "import torch\n",
    "\n",
    "train_dataset = AudioDataset(train_data)\n",
    "val_dataset = AudioDataset(val_data)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sequences, labels_t = zip(*batch)\n",
    "    lengths_t = [seq.size(0) for seq in sequences]\n",
    "    max_length = max(lengths_t)\n",
    "    padded_sequences = torch.zeros(len(sequences), max_length, 20)\n",
    "    padded_labels = torch.zeros(len(sequences), max_length, dtype=torch.long)\n",
    "    for j, seq in enumerate(sequences):\n",
    "        padded_sequences[j, :seq.size(0), :] = seq\n",
    "        padded_labels[j, :len(labels_t[j])] = labels_t[j]\n",
    "    return padded_sequences, padded_labels\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ],
   "id": "2351c796d1a59395",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Training**",
   "id": "7610dd8d5e792cad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T22:18:08.152690Z",
     "start_time": "2025-01-26T22:15:26.578957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from model_classes import AudioClassifierLSTM as AudioClassifier\n",
    "import torch.nn as nn\n",
    "\n",
    "REFRESH_TIME = 0.25  # Refresh time in seconds in future realtime\n",
    "NUM_EPOCHS = 100  # Number of epochs (the more epoch the better model, but it takes more time)\n",
    "PATIENCE_TIME = 10  # Number of epochs without improvement in validation accuracy that will stop training\n",
    "LEARNING_RATE = 0.001  # Learning rate\n",
    "BATCH_SIZE = 16  # Batch size (amount of sequences in one batch)\n",
    "\n",
    "# Check if CUDA is available (learning on GPU is much faster)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device: \", device)\n",
    "\n",
    "total_time = time.time()\n",
    "start_time = time.time()\n",
    "\n",
    "# Create model object\n",
    "print(\"Creating model...\")\n",
    "model = AudioClassifier()\n",
    "model = model.to(device)\n",
    "print(\"Model created, time: \", time.time() - start_time)\n",
    "\n",
    "# Define loss function and optimizer (network parameters)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "# These are just for early stopping\n",
    "best_val_accuracy = 0.0\n",
    "early_stopping_counter = 0\n",
    "\n",
    "print(\"Training model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Iterate through epochs\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    # Enable training on model object\n",
    "    model.train()\n",
    "\n",
    "    # Initialize running loss and accuracy\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    # It's just a fancy progress bar in console\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{NUM_EPOCHS}', unit='batch')\n",
    "\n",
    "    # Iterate through batches\n",
    "    for inputs, labels in progress_bar:\n",
    "\n",
    "        # Move inputs and labels to the device (GPU or CPU)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Jeśli model zwraca więcej niż jedną wartość, przypisz odpowiednią wartość do outputs\n",
    "        if isinstance(outputs, tuple):\n",
    "            outputs = outputs[0]\n",
    "\n",
    "        # Flattening outputs and labels from [batch_size, max_length, num_classes]\n",
    "        outputs = outputs.view(-1, outputs.size(-1))  # Flattening to [batch_size * max_length, num_classes]\n",
    "        labels = labels.view(-1)  # Flattening to [batch_size * max_length]\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass (calculate gradients)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights according to the calculated gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate running loss and accuracy\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        running_accuracy += accuracy_score(labels.cpu(), predicted.cpu())\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix(loss=running_loss / len(progress_bar),\n",
    "                                  accuracy=running_accuracy / len(progress_bar))\n",
    "\n",
    "    # Print the loss and accuracy for the epoch\n",
    "    print('Train Loss: {:.4f}, Train Accuracy: {:.4f}'.format(running_loss / len(train_loader),\n",
    "                                                              running_accuracy / len(train_loader)))\n",
    "\n",
    "    # After training on the whole training set, we can evaluate the model on the validation set\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_running_accuracy = 0.0\n",
    "\n",
    "    # We don't need to calculate gradients during validation\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Iterate through validation set\n",
    "        for inputs, labels in val_loader:\n",
    "\n",
    "            # Move inputs and labels to the device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Jeśli model zwraca więcej niż jedną wartość, przypisz odpowiednią wartość do outputs\n",
    "            if isinstance(outputs, tuple):\n",
    "                outputs = outputs[0]\n",
    "\n",
    "            # As previous, we need to flatten outputs and labels\n",
    "            outputs = outputs.view(-1, outputs.size(-1)) # Flattening to [batch_size * max_length, num_classes]\n",
    "            labels = labels.view(-1) # Flattening to [batch_size * max_length]\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Calculate running loss (cumulative loss over batches) and add current epoch's accuracy to the running (cumulative) accuracy\n",
    "            val_running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_running_accuracy += accuracy_score(labels.cpu(), predicted.cpu())\n",
    "\n",
    "    # Calculate cumulative loss and accuracy for the validation set\n",
    "    avg_val_loss = val_running_loss / len(val_loader)\n",
    "    avg_val_accuracy = val_running_accuracy / len(val_loader)\n",
    "\n",
    "    # And print it\n",
    "    print('Val Loss: {:.4f}, Val Accuracy: {:.4f}'.format(avg_val_loss, avg_val_accuracy))\n",
    "\n",
    "    # Learning rate scheduler (changing learning rate during training)\n",
    "    scheduler.step()\n",
    "\n",
    "    # Early stopping (if there is no improvement in validation accuracy for PATIENCE_TIME epochs, we stop training)\n",
    "    if avg_val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = avg_val_accuracy\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= PATIENCE_TIME:\n",
    "            print(\"Early stopping triggered. No improvement in validation accuracy.\")\n",
    "            break\n",
    "\n",
    "# And print final results\n",
    "print('Finished Training, time: ', time.time() - start_time)\n",
    "print('Saving model...')\n",
    "start_time = time.time()\n",
    "#TODO\n",
    "torch.save(model.state_dict(), 'audio_rnn_classifier.pth')\n",
    "print(\"Model saved, time: \", time.time() - start_time)\n",
    "print(\"Finished, Total time: \", time.time() - total_time)"
   ],
   "id": "f77d53c4715f2c6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n",
      "Creating model...\n",
      "Model created, time:  0.0136566162109375\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 13/13 [00:03<00:00,  3.78batch/s, accuracy=0.393, loss=1.08] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0827, Train Accuracy: 0.3930\n",
      "Val Loss: 1.0525, Val Accuracy: 0.4217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 13/13 [00:03<00:00,  4.30batch/s, accuracy=0.525, loss=0.945] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9446, Train Accuracy: 0.5253\n",
      "Val Loss: 0.7924, Val Accuracy: 0.6855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 13/13 [00:02<00:00,  4.35batch/s, accuracy=0.685, loss=0.723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7235, Train Accuracy: 0.6849\n",
      "Val Loss: 0.7009, Val Accuracy: 0.6701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 13/13 [00:03<00:00,  4.25batch/s, accuracy=0.727, loss=0.629] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6293, Train Accuracy: 0.7267\n",
      "Val Loss: 0.5109, Val Accuracy: 0.7988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 13/13 [00:03<00:00,  3.58batch/s, accuracy=0.801, loss=0.492] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4916, Train Accuracy: 0.8015\n",
      "Val Loss: 0.4248, Val Accuracy: 0.8322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 13/13 [00:04<00:00,  2.77batch/s, accuracy=0.837, loss=0.421] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4214, Train Accuracy: 0.8373\n",
      "Val Loss: 0.4098, Val Accuracy: 0.8411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 13/13 [00:03<00:00,  3.26batch/s, accuracy=0.866, loss=0.355]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3552, Train Accuracy: 0.8657\n",
      "Val Loss: 0.3558, Val Accuracy: 0.8612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 13/13 [00:04<00:00,  2.98batch/s, accuracy=0.857, loss=0.379] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3792, Train Accuracy: 0.8571\n",
      "Val Loss: 0.3603, Val Accuracy: 0.8689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 13/13 [00:04<00:00,  3.05batch/s, accuracy=0.874, loss=0.335] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3354, Train Accuracy: 0.8744\n",
      "Val Loss: 0.3500, Val Accuracy: 0.8632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 13/13 [00:04<00:00,  2.83batch/s, accuracy=0.878, loss=0.323] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3231, Train Accuracy: 0.8779\n",
      "Val Loss: 0.3212, Val Accuracy: 0.8773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 13/13 [00:04<00:00,  3.14batch/s, accuracy=0.885, loss=0.301] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3013, Train Accuracy: 0.8849\n",
      "Val Loss: 0.3137, Val Accuracy: 0.8779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 13/13 [00:04<00:00,  2.77batch/s, accuracy=0.89, loss=0.299]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2990, Train Accuracy: 0.8895\n",
      "Val Loss: 0.3170, Val Accuracy: 0.8778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 13/13 [00:04<00:00,  2.83batch/s, accuracy=0.889, loss=0.29]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2904, Train Accuracy: 0.8894\n",
      "Val Loss: 0.3094, Val Accuracy: 0.8826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 13/13 [00:04<00:00,  2.81batch/s, accuracy=0.896, loss=0.282] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2818, Train Accuracy: 0.8961\n",
      "Val Loss: 0.3151, Val Accuracy: 0.8799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 13/13 [00:04<00:00,  2.98batch/s, accuracy=0.895, loss=0.278] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2775, Train Accuracy: 0.8949\n",
      "Val Loss: 0.2913, Val Accuracy: 0.8947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 13/13 [00:04<00:00,  3.11batch/s, accuracy=0.902, loss=0.265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2651, Train Accuracy: 0.9017\n",
      "Val Loss: 0.2963, Val Accuracy: 0.8928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 13/13 [00:04<00:00,  3.12batch/s, accuracy=0.9, loss=0.265]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2652, Train Accuracy: 0.8999\n",
      "Val Loss: 0.2950, Val Accuracy: 0.8923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 13/13 [00:03<00:00,  3.43batch/s, accuracy=0.903, loss=0.263] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2628, Train Accuracy: 0.9026\n",
      "Val Loss: 0.3094, Val Accuracy: 0.8845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 13/13 [00:04<00:00,  2.77batch/s, accuracy=0.9, loss=0.26]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2602, Train Accuracy: 0.8998\n",
      "Val Loss: 0.3045, Val Accuracy: 0.8903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 13/13 [00:04<00:00,  2.79batch/s, accuracy=0.905, loss=0.253] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2526, Train Accuracy: 0.9048\n",
      "Val Loss: 0.2942, Val Accuracy: 0.8957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 13/13 [00:04<00:00,  2.80batch/s, accuracy=0.905, loss=0.248] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2482, Train Accuracy: 0.9055\n",
      "Val Loss: 0.2962, Val Accuracy: 0.8956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 13/13 [00:04<00:00,  3.00batch/s, accuracy=0.906, loss=0.247] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2470, Train Accuracy: 0.9060\n",
      "Val Loss: 0.2940, Val Accuracy: 0.8972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 13/13 [00:04<00:00,  3.16batch/s, accuracy=0.907, loss=0.245] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2450, Train Accuracy: 0.9071\n",
      "Val Loss: 0.2918, Val Accuracy: 0.8987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 13/13 [00:04<00:00,  3.08batch/s, accuracy=0.907, loss=0.241] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2412, Train Accuracy: 0.9075\n",
      "Val Loss: 0.3010, Val Accuracy: 0.8928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 13/13 [00:04<00:00,  3.06batch/s, accuracy=0.908, loss=0.24]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2405, Train Accuracy: 0.9084\n",
      "Val Loss: 0.2914, Val Accuracy: 0.8984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 13/13 [00:04<00:00,  3.07batch/s, accuracy=0.909, loss=0.24]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2405, Train Accuracy: 0.9086\n",
      "Val Loss: 0.2997, Val Accuracy: 0.8935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 13/13 [00:04<00:00,  3.11batch/s, accuracy=0.91, loss=0.237]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2374, Train Accuracy: 0.9103\n",
      "Val Loss: 0.2939, Val Accuracy: 0.8989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 13/13 [00:03<00:00,  3.25batch/s, accuracy=0.911, loss=0.234] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2339, Train Accuracy: 0.9115\n",
      "Val Loss: 0.2982, Val Accuracy: 0.8967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 13/13 [00:04<00:00,  3.22batch/s, accuracy=0.911, loss=0.236] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2360, Train Accuracy: 0.9111\n",
      "Val Loss: 0.2964, Val Accuracy: 0.8981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 13/13 [00:04<00:00,  3.17batch/s, accuracy=0.913, loss=0.234] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2344, Train Accuracy: 0.9126\n",
      "Val Loss: 0.2961, Val Accuracy: 0.8977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 13/13 [00:04<00:00,  3.10batch/s, accuracy=0.912, loss=0.234] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2339, Train Accuracy: 0.9125\n",
      "Val Loss: 0.2973, Val Accuracy: 0.8972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████| 13/13 [00:04<00:00,  3.08batch/s, accuracy=0.911, loss=0.231] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2306, Train Accuracy: 0.9112\n",
      "Val Loss: 0.2980, Val Accuracy: 0.8969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████| 13/13 [00:04<00:00,  3.16batch/s, accuracy=0.911, loss=0.237] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2367, Train Accuracy: 0.9112\n",
      "Val Loss: 0.2967, Val Accuracy: 0.8972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████| 13/13 [00:04<00:00,  3.11batch/s, accuracy=0.913, loss=0.229] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2294, Train Accuracy: 0.9130\n",
      "Val Loss: 0.2983, Val Accuracy: 0.8971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████| 13/13 [00:04<00:00,  3.08batch/s, accuracy=0.912, loss=0.228] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2284, Train Accuracy: 0.9120\n",
      "Val Loss: 0.2971, Val Accuracy: 0.8978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████| 13/13 [00:03<00:00,  3.33batch/s, accuracy=0.913, loss=0.228] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2276, Train Accuracy: 0.9131\n",
      "Val Loss: 0.2981, Val Accuracy: 0.8964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████| 13/13 [00:04<00:00,  2.89batch/s, accuracy=0.911, loss=0.229] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2293, Train Accuracy: 0.9115\n",
      "Val Loss: 0.2988, Val Accuracy: 0.8968\n",
      "Early stopping triggered. No improvement in validation accuracy.\n",
      "Finished Training, time:  161.5369589328766\n",
      "Saving model...\n",
      "Model saved, time:  0.010174989700317383\n",
      "Finished, Total time:  161.56196188926697\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4920c770ed8d9224",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
